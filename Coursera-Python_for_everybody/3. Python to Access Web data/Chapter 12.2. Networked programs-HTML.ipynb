{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scrapping or Web Crawling (aka parsing HTML)\n",
    "- Term used for writting applications that pretend to be web browers and retrieves the links of that web pages\n",
    "- Web browser Request-REsponse cycle, we click on the links\n",
    "- we will do the same with python by parsing (not clicking)\n",
    "<img src ='web_scrap.png'>\n",
    "\n",
    "### Why scrape?\n",
    "- pull data (social data)\n",
    "- monitor a site for new info\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing HTML with BeautifulSoup\n",
    "- using \"BeautifulSoup\" library\n",
    "- Steps:\n",
    "    - Retrieve the webpage\n",
    "    - Parse the Webpage\n",
    "    - look at the anchor tags \n",
    "    - print out the hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = raw_input('Enter - ')\n",
    "\n",
    "html = urllib.urlopen(url).read() # read it all --> gives all lines\n",
    "                                  # html is a string\n",
    "soup = BeautifulSoup(html)        # soup object: parsed html data\n",
    "\n",
    "#retrieve a list of the ancho tags  <a> ....</a>  so, find me all the tags\n",
    "tags = soup('a')\n",
    "# inside the <a>...href=\"xxxx\"...</a> there are atributes such as href =\"xxx\".\n",
    "# soup parses these attributes as a key-value pairs like in a dictionary\n",
    "\n",
    "for tag in tags:\n",
    "    print tag.get('href',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://www.dr-chuck.com\n",
      "http://www.dr-chuck.com/csev-blog/\n",
      "http://www.si.umich.edu/\n",
      "http://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\n",
      "http://www.dr-chuck.com/csev-blog\n",
      "http://www.twitter.com/drchuck/\n",
      "http://www.dr-chuck.com/dr-chuck/resume/speaking.htm\n",
      "http://www.slideshare.net/csev\n",
      "/dr-chuck/resume/index.htm\n",
      "http://amzn.to/1K5Q81K\n",
      "http://afs.dr-chuck.com/papers/\n",
      "https://itunes.apple.com/us/podcast/computing-conversations/id731495760\n",
      "http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "http://developers.imsglobal.org/\n",
      "http://www.youtube.com/user/csev\n",
      "http://vimeo.com/drchuck/videos\n",
      "https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\n",
      "http://www.linkedin.com/pub/chuck-severance/2/92a/3a8\n",
      "https://www.researchgate.net/profile/Charles_Severance/\n",
      "http://www.tsugi.org/\n",
      "http://youtu.be/slscHD40r78\n",
      "https://www.coursera.org/course/pythonlearn\n",
      "https://www.coursera.org/course/insidetheinternet\n",
      "http://open.umich.edu/education/si/si502/winter2009/\n",
      "http://www.pythonlearn.com\n",
      "http://www.php-intro.com/\n",
      "http://www.appenginelearn.com\n",
      "http://www.pythonlearn.com/\n",
      "/sakai-book\n",
      "http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20\n",
      "http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20\n",
      "http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\n",
      "http://oreilly.com/catalog/9781565923126/\n",
      "http://cnx.org/content/col11136/latest/\n",
      "http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "http://www.vimeo.com/17207620\n",
      "http://www.youtube.com/watch?v=BVKpW02hsrU\n",
      "http://www.youtube.com/watch?v=sa2WsgCvn7c\n",
      "http://www.vimeo.com/17213019\n",
      "http://www.youtube.com/watch?v=FJ078sO35M0\n",
      "http://afs.dr-chuck.com/citoolkit\n",
      "http://www.sakaiproject.org/\n",
      "http://www.tsugi.org/ target=\n",
      "http://developers.imsglobal.org/\n",
      "/obi-sample\n",
      "https://twitter.com/drchuck\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "url = raw_input('Enter - ')\n",
    "html = urllib.urlopen(url).read()                          \n",
    "soup = BeautifulSoup(html)      \n",
    "tags = soup('a')\n",
    "\n",
    "for tag in tags:\n",
    "    print tag.get('href',None)\n",
    "# enter this url http://www.dr-chuck.com/page1.htm\n",
    "# or enter: http://www.dr-chuck.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSIGNMENT \"SCRAPING HTML DATA WITH BEAUTIFUL SOUP\"\n",
    "- USE URL TO READ html\n",
    "- PARSE THE DATA\n",
    "- Extract number\n",
    "- compute the sum of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2553"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "url = \"http://python-data.dr-chuck.net/comments_42.html\"\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)      \n",
    "tags = soup('span')\n",
    "lst= list()\n",
    "for tag in tags:\n",
    "    num = int(tag.contents[0])\n",
    "    lst.append(num)\n",
    "sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2806"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = \"http://python-data.dr-chuck.net/comments_283166.html\"\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)      \n",
    "tags = soup('span')\n",
    "lst= list()\n",
    "for tag in tags:\n",
    "    num = int(tag.contents[0])  # extract the first value of the content in <span>\n",
    "    lst.append(num)             # adds all numbers into a list\n",
    "sum(lst)                        # sum all numbers of the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT \"FOLLOWING LINKS IN HTML USING BEAUTIFULSOUP\"\n",
    "- urllib read the HTML\n",
    "- extract href= values from anchor tags\n",
    "- scan a particular tag\n",
    "- follow th link\n",
    "- repeat the process\n",
    "- report the last name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter position:3\n",
      "Enter count:4\n",
      "Retriving: http://python-data.dr-chuck.net/known_by_Anayah.html\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = \"http://python-data.dr-chuck.net/known_by_Fikret.html\"\n",
    "lst = list()\n",
    "position = int(raw_input('Enter position:'))\n",
    "count = int(raw_input('Enter count:'))\n",
    "for i in range(count):\n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)      \n",
    "    tags = soup('a')\n",
    "    for tag in tags:\n",
    "        lst.append(tag)\n",
    "    url = lst[position-1].get('href',None)\n",
    "    del lst[:]\n",
    "            \n",
    "\n",
    "print \"Retriving:\", url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter position:1\n",
      "Enter count:1\n",
      "Retriving: http://python-data.dr-chuck.net/known_by_Zhi.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-9fb2e399cec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Retriving:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = \"http://python-data.dr-chuck.net/known_by_Lochlann.html\"\n",
    "\n",
    "lst = list()\n",
    "position = int(raw_input('Enter position:'))\n",
    "count = int(raw_input('Enter count:'))\n",
    "for i in range(count):\n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)      \n",
    "    tags = soup('a')\n",
    "    for tag in tags:\n",
    "        lst.append(tag)\n",
    "    url = lst[position-1].get('href',None)\n",
    "    del lst[:]\n",
    "    print \"Retriving:\", url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
